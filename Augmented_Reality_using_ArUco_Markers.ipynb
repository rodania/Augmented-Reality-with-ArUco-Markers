{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "from operator import itemgetter, attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(dicIds):\n",
    "    \"\"\"\n",
    "    The function take the detected marckers in a dictionary format\n",
    "    and returns the frame of the video\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the upper boundary of the frame\n",
    "    # sort the markers according to the Y-cor and take the last two markers\n",
    "    top_Markers_pts = sorted(sorted({v[0] for v in markers.values()} , key=itemgetter(1))[-2:], reverse=True)\n",
    "    # get the ids of these markers\n",
    "    top_Markers_ids = [k for pt in top_Markers_pts for k, v in markers.items() if pt == v[0]]\n",
    "\n",
    "    # sort the markers according to the Y-cor and take the first two markers\n",
    "    bottom_Markers_pts = sorted(sorted({v[0] for v in markers.values()} , key=itemgetter(1))[0:2])\n",
    "    # get the ids of these markers\n",
    "    bottom_Markers_ids = [k for pt in bottom_Markers_pts for k, v in markers.items() if pt == v[0]]\n",
    "    \n",
    "    # combine sorted ids together\n",
    "    sortedIds = bottom_Markers_ids + top_Markers_ids\n",
    "\n",
    "    # return the border of the frame\n",
    "    showingBorder = [markers[sortedIds[0]][0], markers[sortedIds[1]][1], \n",
    "                         markers[sortedIds[2]][2], markers[sortedIds[3]][3]]\n",
    "    return showingBorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video to show\n",
    "myVid = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# activate mobile camera\n",
    "address = \"http://192.168.0.9:8080/video\"\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.open(address)\n",
    "\n",
    "# create empty dictionary to save markers in \n",
    "markers = {}\n",
    "\n",
    "# call ArUco marker dictionary\n",
    "dictionary = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "parameters = aruco.DetectorParameters_create()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Detect the markers in the image\n",
    "    corners, ids, rejected = cv2.aruco.detectMarkers(frame, dictionary, parameters=parameters)\n",
    "    \n",
    "    # check if the 4 corners of the marker is dected\n",
    "    if len(corners) > 0:\n",
    "        # flatten the ArUco IDs list\n",
    "        ids = ids.flatten()\n",
    "\n",
    "        # loop over the detected ArUCo corners\n",
    "        for (markerCorners, markerID) in zip(corners, ids):\n",
    "            # extract the marker corners (which are always returned in\n",
    "            # top-right, top-left, bottom-left, and bottom-right order)\n",
    "            corners = markerCorners.reshape((4, 2))\n",
    "            \n",
    "            # add detected pts to marker dictionary\n",
    "            markers[markerID] = list(map(tuple, corners))\n",
    "            \n",
    "        # if the four markers are detcted call getFrame function to get the boundary of the showing area\n",
    "        if len(markers) == 4:\n",
    "            showingBorder = np.float32(getFrame(markers))    \n",
    "\n",
    "            # mask the refrenced object\n",
    "            markerArea = cv2.fillPoly(frame, np.int32([showingBorder]), (0, 0, 0), lineType=cv2.LINE_AA) \n",
    "\n",
    "            # read the video\n",
    "            success, inputVid = myVid.read()            \n",
    "            (hVideo, wVideo) = inputVid.shape[:2]\n",
    "\n",
    "            # get frame border of the video to transform it to the marker area\n",
    "            InputVidBorder = np.float32([[0, 0], [wVideo, 0], [wVideo, hVideo], [0, hVideo]])\n",
    "\n",
    "            # Calculate transformation matrix\n",
    "            matrix = cv2.getPerspectiveTransform(InputVidBorder, showingBorder)\n",
    "\n",
    "            # warp video to the referenced marker\n",
    "            warpVid = cv2.warpPerspective(inputVid, matrix, (frame.shape[1], frame.shape[0])) \n",
    "            output = cv2.add(markerArea, warpVid)\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('frame', output)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    else:\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "# When everything done, release the capture\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
